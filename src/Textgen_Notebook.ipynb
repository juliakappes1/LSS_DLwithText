{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNNs with Keras\n",
    "\n",
    "nach dem Tut aus: https://github.com/llSourcell/keras_explained/blob/master/gentext.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m = Bidirectional(CuDNNLSTM(cfg['rnn_size'],return_sequences=True),\n",
    "                                 name='rnn_{}'.format(layer_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 185697\n"
     ]
    }
   ],
   "source": [
    "#path = get_file('bundestag.txt', origin='https://www.bundestag.de/blob/569484/7b0f24562fb8ddcbc26f6b4c0591d8f8/19050-data.xml')\n",
    "text = io.open(\"trump.txt\", encoding='utf-8').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a true honor to receive the endorsement of john wayne s daughter read.\\n a nearly impossible path to the gop nomination for rubio says.\\n newyork tromps jonas day after storm of the century the big city is up and running unlike others in the northeast must be newyorkvalues.\\n i love those beautiful gals d s two amazing women.\\n thank you nevada trump2016 makeamericagreatagain username realdonaldtrump.\\n can you imagine if i had the small crowds that hillary is drawing today in pennsylvania it would be a major media event.\\n we are already live in everett wa for the trump rally come join us our cameras tonight trumpineverett.\\n really sad that republicans would allow themselves to be used in a clinton ad lindsey graham romney flake sass supreme court remember.\\n our incompetent secretary of state hillary clinton was the one who started talks to give 400 million dollars in cash to iran scandal.\\n wow is in total disarray with almost everybody quitting good news bad dishonest journalists.\\n so many'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 39\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '.', '0', '1', '2', '3', '4', '5', '6']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 61886\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a true honor to receive the endorsement ',\n",
       " 'rue honor to receive the endorsement of ',\n",
       " ' honor to receive the endorsement of joh',\n",
       " 'nor to receive the endorsement of john w',\n",
       " ' to receive the endorsement of john wayn',\n",
       " ' receive the endorsement of john wayne s',\n",
       " 'ceive the endorsement of john wayne s da',\n",
       " 've the endorsement of john wayne s daugh',\n",
       " 'the endorsement of john wayne s daughter',\n",
       " ' endorsement of john wayne s daughter re']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False]\n",
      "61886\n"
     ]
    }
   ],
   "source": [
    "# input\n",
    "print(x[0][0])\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61886\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "61886/61886 [==============================] - 105s 2ms/step - loss: 2.2047\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"mericafirst.\n",
      " other than a small group o\"\n",
      "mericafirst.\n",
      " other than a small group on will to and to and the will a dolinat and the will be a to and the will the will be wast a doon to all call the will trump call the will the will to as doons the will be will be to the will to and the will be to all that the will be will be to and the seating to ame that the will to and and the will be will be to the will the told the will the a tomant on the will to america greatagain trump rep\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"mericafirst.\n",
      " other than a small group o\"\n",
      "mericafirst.\n",
      " other than a small group ous and presids and the soot werser to on will be sardect all cruz a poople on incalled at caid is pall trump cilling interation trump the will the will hast nepars that i ways herd nemere is a tous a trump trump lieser wo to shoull gouted on ore fors a the wall the our the will be to stould one the wate america lais mearicanion now all the sadine wall calling the dovation a to a court hillary not \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"mericafirst.\n",
      " other than a small group o\"\n",
      "mericafirst.\n",
      " other than a small group obletens ouneas trumpace topgephece dofaytans on ann bece voted biscan to ntweven todowa wraked great wist kgayis to days haf to nad and tokuastallahtiout lisicattingngatice great hiolognedertevery.\n",
      " for takeda.\n",
      " was deestaseig ansdhilla.\n",
      " s hert petursignetstat.\n",
      " on werker a fars we woy daseshour s ald toully s ited bomb usthodmeng wow theat ou rherin intect1y hall didaiteld and dio sievess tread \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"mericafirst.\n",
      " other than a small group o\"\n",
      "mericafirst.\n",
      " other than a small group on whaselinion.\n",
      " nety trump shomle.\n",
      " morestry oponghe.\n",
      " milied eal marstout.\n",
      " 1sbo2pyeple fout mirald spariciagountryush and ghe giegriseci ways wpleffucallly lomipeot 6 we neals weal bolh o seald cepponstumedhts.\n",
      " vesw be ale t0ike vick khopniw snemy fisomert f rewiren dacterd fott the wyare wyridamahis e2d dassernater pany 4a0medicay 0 buag othey liakeating we se arb 6zomejadadime ani laoiz are r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3ccf2b198>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
